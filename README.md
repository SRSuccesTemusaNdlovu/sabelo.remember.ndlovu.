# Data Engineer | Data Warehouse Engineer | Data Analyst 

ğŸ“ Johannesburg, South Africa  
ğŸ“§ sabelo.remember.ndlovu@gmail.com  
ğŸ“± 076 819 9714  

---

## ğŸ‘‹ About Me  
Iâ€™m a dynamic data engineering professional with a knack for transforming complex data into actionable insights. Iâ€™ve earned the **IBM Data Engineering Professional Certificate**, mastered **Data Warehousing**, and became proficient in **Azure**, **Databricks**, and **SQL**. Iâ€™m passionate about leveraging **Microsoft Fabric** to optimize workflows and drive innovation.  

---

## ğŸ’¼ Employment History  
### Data Engineer Recruit â€“ Umuzi, Johannesburg  
**March 2024 â€“ March 2025**

- Developed and optimized robust **ETL/ELT pipelines** using **Microsoft Fabric Dataflows Gen2** for ingesting structured and semi-structured data.  
- Designed and implemented scalable data infrastructure using **OneLake** and **Lakehouse architecture** in Microsoft Fabric.  
- Built **Lakehouse-to-Warehouse pipelines** to enable real-time reporting and analytics in **Power BI**.  
- Utilized **Fabric Notebooks (Python & Spark)** for data exploration, transformation, and automation of large-scale data processing tasks.  
- Integrated **Azure Data Factory** and **Fabric Pipelines** to orchestrate end-to-end workflows across various cloud services.  
- Created and managed **semantic models** to enable self-service BI through **Direct Lake mode**, minimizing latency and maximizing performance.  
- Optimized **SQL queries** within Fabric environments to ensure fast and efficient data access.  
- Collaborated in an agile team, using **GitHub** for version control and **GitHub Actions** for CI/CD on Fabric-based deployments.  
- Ensured data quality and lineage through **Data Quality Rules** and **Lineage Views** in Fabric.  
- Delivered data for dashboards, reports, and insights used by stakeholders across departments.


**Mathematics Teacher** â€“ Likhweti Primary School, Nelspruit  
*January 2023 â€“ February 2024*  
- Taught Grade 7 Mathematics, focusing on problem-solving.  
- Designed interactive lessons and provided individualized support.

---

## ğŸ“ Education  

**National Senior Certificate** â€“ Sicelosethu Secondary School  
*Mpumalanga, 2016*  

**BSc in Mathematical and Computer Science** â€“ University of Limpopo  
*2019 â€“ 2021 (On hold due to financial reasons)*  

---

## ğŸ“œ Certificates  

- IBM Data Engineering Professional Certificate 
- IBM Data Warehouse Professional Certificate 
- Microsoft Azure Fundamentals (DP-900)
- Google Data Analytics Professional Certificate
- Microsoft Fabric Certificate
- Azure Databricks & Spark and Microsoft Fabric 

---

## ğŸ’¡ Skills

### ğŸ› ï¸ Data Engineering  
- Building scalable data pipelines (ETL/ELT)  
- Handling batch and streaming data flows  
- Data ingestion from APIs, cloud sources, and files  
- Data cleansing, transformation, and validation  
- Workflow orchestration using Apache Airflow and Microsoft Fabric pipelines  

### ğŸ—„ï¸ Data Warehousing  
- Designing modern data warehouses with **Microsoft Fabric Lakehouse**  
- Implementing **OneLake**, **Direct Lake**, and **Delta Lake** for scalable storage  
- Building semantic models for business intelligence  
- Dimensional modeling (Star and Snowflake schemas)  
- Experience with **IBM Db2**, **Azure Synapse**, and **Microsoft Fabric Warehouse**  

### ğŸŒ Cloud Platforms & Big Data  
- **Microsoft Azure** (Blob Storage, Data Factory, Azure SQL, Synapse)  
- **Azure Databricks** (PySpark, MLlib, Delta Lake)  
- **Microsoft Fabric** (Dataflows Gen2, Lakehouse, Notebooks, Pipelines)  
- Familiarity with IBM Cloud Services  

### ğŸ“Š Data Analytics & Visualization  
- **Power BI** for dashboarding and business reporting  
- **Google Data Studio / Looker Studio**  
- Data storytelling and stakeholder reporting  
- Exploratory Data Analysis (EDA) and visual insights  
- DAX expressions for modeling and calculations  

### ğŸ§  Machine Learning & Statistics  
- Implementing ML workflows with **Spark MLlib**  
- Regression, Classification, Feature Engineering  
- Train-test splitting and model evaluation techniques  

### ğŸ’¾ Databases & Querying  
- SQL (joins, subqueries, window functions, optimization)  
- Microsoft Fabric SQL, **PostgreSQL**, **MySQL**, **IBM Db2**, **Azure SQL Database**  
- Understanding of NoSQL concepts (covered in Fabric and Azure ecosystem)  
- Query tuning and performance monitoring  

### ğŸ‘¨â€ğŸ’» Programming & Tools  
- Python (Pandas, NumPy, requests, datetime, Spark APIs)  
- Git & GitHub (version control, CI/CD basics)  
- Jupyter Notebooks & Fabric Notebooks  
- Working with structured data: JSON, CSV, Parquet, Excel  
- Consuming and building RESTful APIs  

### ğŸ”§ Workflow & DevOps  
- Data pipeline orchestration using **Microsoft Fabric Pipelines**  
- GitHub Actions for automation  
- Data quality checks and monitoring  
- Agile workflows and collaborative development  

## ğŸš€ Projects

### ğŸ Python Projects

ğŸ”¹ **[Consume GitHub API with Python](https://github.com/SRSuccesTemusaNdlovu/Consume-GitHub-Api)**  
Fetches pull requests with filtering, pagination, and rate limit handling using the GitHub API.  
**Tech Used**: Python, Requests, GitHub REST API, Pytest

ğŸ”¹ **[Bank Account & Interest Calculator](https://github.com/SRSuccesTemusaNdlovu/Bank-Account---Interest-Calculator)**  
Simulates a banking system with interest calculations and robust error handling.  
**Tech Used**: Python, OOP, Decimal, Pytest

ğŸ”¹ **[VisitorTracker: JSON-Based Visitor Management](https://github.com/SRSuccesTemusaNdlovu/VisitorTracker-JSON-Based-Visitor-Management)**  
Tracks visitors using a JSON-based file system without a database.  
**Tech Used**: Python, OOP, File I/O, Assertions

ğŸ”¹ **[Password Strength Checker](https://github.com/SRSuccesTemusaNdlovu/Password-sStrength-Checker)**  
Evaluates the strength of passwords using rule-based logic.  
**Tech Used**: Python, Pytest

ğŸ”¹ **[String Calculator](https://github.com/SRSuccesTemusaNdlovu/The-String-Calculator-project)**  
Parses and sums numbers from string input with custom delimiter support.  
**Tech Used**: Python, Pytest

ğŸ”¹ **[Validate South African ID](https://github.com/SRSuccesTemusaNdlovu/Validate-South-African-ID)**  
Validates South African ID numbers using format rules and Luhn algorithm.  
**Tech Used**: Python, Pytest

ğŸ”¹ **[Shopping Basket Analysis](https://github.com/SRSuccesTemusaNdlovu/Shopping-Basket-Analysis)**  
Analyzes customer shopping behavior using Python-based logic.  
**Tech Used**: Python

---

### ğŸ§  Data Analysis Projects

ğŸ”¹ **[Retail Sales Data Analysis](https://github.com/SRSuccesTemusaNdlovu/Retail-Sales-Data-Analysis)**  
Performs sales analysis and customer insights using SQL queries.  
**Tech Used**: PostgreSQL

ğŸ”¹ **[Data Wrangling for Personality Risk Profiling](https://github.com/SRSuccesTemusaNdlovu/Data-Wrangling-and-Analysis-for-Personality-Risk-Profiling)**  
Analyzes personality data to determine applicant risk profiles.  
**Tech Used**: Pandas

ğŸ”¹ **[Shopping Basket Analysis](https://github.com/SRSuccesTemusaNdlovu/Shopping-Basket-Analysis)**  
Performs exploratory analysis on customer purchase patterns.  
**Tech Used**: Python

---

### ğŸ—ƒï¸ Database Projects

ğŸ”¹ **[SQL Shop Database](https://github.com/SRSuccesTemusaNdlovu/Sql-Shop-Database)**  
Designs and implements a relational database for shop operations.  
**Tech Used**: PostgreSQL, Docker Compose

ğŸ”¹ **[Python and MongoDB](https://github.com/SRSuccesTemusaNdlovu/Python-and-MongoDB)**  
Implements a visitor tracking system using MongoDB and Python.  
**Tech Used**: Python, Pymongo, Mongomock, Docker Compose

ğŸ”¹ **[Library Management System](https://github.com/SRSuccesTemusaNdlovu/Library-Management-System)**  
This project demonstrates the implementation of a Library Management System using SQL.  
**Tech Used**: PostgreSQL

### ğŸ› ï¸ Data Engineering Projects

ğŸ”¹ **[CircuitFlow: A Spark Data Engineering Pipeline](https://github.com/SRSuccesTemusaNdlovu/Spark-Data-Engineering-Pipeline)**  
An end-to-end data pipeline that reads raw CSV data from Azure Lakehouse, transforms it with PySpark, and writes the results to a processed zone in Parquet format.

**Tech Used**: PySpark, Azure OneLake, Data Lakehouse, Structured Streaming (optional), ETL Design

---

## ğŸ“« Let's Connect  
- [LinkedIn](https://www.linkedin.com/in/sabelo-remember-ndlovu)  
- [GitHub](https://srsuccestemusandlovu.github.io/)



